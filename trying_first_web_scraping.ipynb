{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5a465ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d34d4bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requests - performs the URL request and fetches the website's HTML\n",
    "# time - limits how many times we scrape the page at once\n",
    "# csv - helps us export our scraped data to a CSV file\n",
    "# re - allows us to write regular expressions that will come in handy for picking text based on its pattern\n",
    "# bs4 -  the scraping module to parse the HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbfedf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(source_url,soup):\n",
    "    # finding all the elements of all books\n",
    "    books= soup.find_all(\"article\", class_=\"product_pod\")\n",
    "    \n",
    "    \n",
    "    # iterating over each element of each book\n",
    "    for each_book in books:\n",
    "        info_url= source_url+\"/\"+each_book.h3.find(\"a\")[\"href\"]\n",
    "        cover_url=source_url+\"/catalogue\" +each_book.a.img[\"src\"].replace(\"..\",\"\")\n",
    "        \n",
    "        \n",
    "        title= each_book.h3.find(\"a\")[\"title\"]\n",
    "        rating= each_book.find(\"p\", class_=\"star-rating\")[\"class\"][1]\n",
    "        price= each_book.find(\"p\", class_=\"price_color\").text.strip().encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "        availability= each_book.find(\"p\", class_=\"instock availability\").text.strip()\n",
    "        \n",
    "        \n",
    "        # Invoke the write to csv funtion\n",
    "        \n",
    "        write_to_csv([info_url,cover_url,title,rating,price,availability])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a34805e9",
   "metadata": {},
   "outputs": [],
   "source": [
    " def write_to_csv(list_input):\n",
    "        # the scraped info will be written here\n",
    "        try:\n",
    "            with open(\"allbooks.csv\",\"a\") as fopen:\n",
    "                csv_writer=csv.writer(fopen)\n",
    "                csv_writer.writerow(list_input)\n",
    "        except:\n",
    "            return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b4046c1",
   "metadata": {},
   "outputs": [],
   "source": [
    " def browse_and_scrape(seed_url, page_no=1):\n",
    "        url_pat = re.compile(r\"(http://.*\\.com)\")\n",
    "        source_url= url_pat.search(seed_url).group(0)  #fetchimg th url\n",
    "        \n",
    "        formatted_url=seed_url.format(str(page_no))\n",
    "        \n",
    "        try:\n",
    "            html_text=requests.get(formatted_url).text\n",
    "            soup= BeautifulSoup(html_text,\"html.parser\")\n",
    "            print(f\"Now Scraping..{formatted_url}\")\n",
    "            \n",
    "            if soup.find(\"li\", class_=\"next\")!= None:  # the function will stop if finds an empty page\n",
    "                scrape(source_url,soup)     # invoke the scrape function\n",
    "                \n",
    "                time.sleep(3)\n",
    "                page_no+=1\n",
    "                \n",
    "                browse_and_scrape(seed_url,page_no)    #increment the page_no and call the browse_and_scrape function again\n",
    "                \n",
    "            else:\n",
    "                scrape(source_url,soup)\n",
    "                return True\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            return e\n",
    "        \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72a445c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web scraping has begun\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-1.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-2.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-3.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-4.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-5.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-6.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-7.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-8.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-9.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-10.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-11.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-12.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-13.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-14.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-15.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-16.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-17.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-18.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-19.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-20.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-21.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-22.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-23.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-24.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-25.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-26.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-27.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-28.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-29.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-30.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-31.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-32.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-33.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-34.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-35.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-36.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-37.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-38.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-39.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-40.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-41.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-42.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-43.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-44.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-45.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-46.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-47.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-48.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-49.html\n",
      "Now Scraping..http://books.toscrape.com/catalogue/page-50.html\n",
      "Web scraping is now complete!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    seed_url = \"http://books.toscrape.com/catalogue/page-{}.html\"\n",
    "    print(\"Web scraping has begun\")\n",
    "    result = browse_and_scrape(seed_url)\n",
    "    if result == True:\n",
    "        print(\"Web scraping is now complete!\")\n",
    "    else:\n",
    "        print(f\"Oops, That doesn't seem right!!! - {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18993ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ca5341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
